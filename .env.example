# Manim GPT Environment Configuration

# ======================
# Logging Configuration
# ======================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
LOG_LEVEL=INFO

# Log format: "human" for human-readable logs, "json" for structured JSON logs
# Default: human
# Use "json" for production environments to enable log aggregation and parsing
LOG_FORMAT=human

# Log file path (optional)
# If not set, logs will only be written to stdout
# Example: LOG_FILE=./logs/manim-gpt.log
# LOG_FILE=

# LiteLLM log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: WARNING (to reduce noise from LiteLLM library)
LITELLM_LOG_LEVEL=WARNING

# ======================
# API Configuration
# ======================

# API URL for Gradio UI
# Default: http://localhost:8000
API_URL=http://localhost:8000

# Port for Gradio UI
# Default: 7860
# PORT=7860

# ======================
# LLM Configuration
# ======================

# Add your LLM API keys here
# OPENAI_API_KEY=your_openai_api_key
# ANTHROPIC_API_KEY=your_anthropic_api_key
# GROQ_API_KEY=your_groq_api_key
# CEREBRAS_API_KEY=your_cerebras_api_key
